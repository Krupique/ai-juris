{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Juris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import shutil\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folders do not exist or have already been removed!\n"
     ]
    }
   ],
   "source": [
    "# Removes folders if they already exist. This avoids errors when running jupyter from the second time onwards\n",
    "try:\n",
    "    shutil.rmtree('train_logs')\n",
    "    shutil.rmtree('train_results')\n",
    "    shutil.rmtree('saved_model')\n",
    "except:\n",
    "    print('The folders do not exist or have already been removed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576e195d46af4e53bdfa841087bd210e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1970\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 493\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File name\n",
    "filename = 'data/input_dataset.csv'\n",
    "\n",
    "# Load data\n",
    "dataset = load_dataset('csv', data_files=filename)\n",
    "\n",
    "# Splitting into training and testint with 80/20 ratio\n",
    "dataset = dataset['train'].train_test_split(test_size = 0.2)\n",
    "\n",
    "# Show dataset format\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer and LLM Open-Source\n",
    "\n",
    "https://huggingface.co/google/flan-t5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
    "\n",
    "# Showing the tokenizer\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained LLM\n",
    "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
    "\n",
    "# Show the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator to concatenate the tokenizer and the model\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# Show the Data Collator\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every input will receive the prefix: \"answer the question\"\n",
    "prefix = \"answer the question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def data_preprocess(data):\n",
    "    # Concatenate the prefix to each question in the list of questions given in data[\"question\"]\n",
    "    inputs = [prefix + doc for doc in data['question']]\n",
    "\n",
    "    # Uses the tokenizer to convert the processed questions into tokens with a maximum lenght of 128, truncating any that are longer\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "\n",
    "    # Tokenize the responses given in data['answer] with a maximum lenght of 512, truncating any that are longer\n",
    "    labels = tokenizer(text_target = data['answer'], max_length=512, truncation=True)\n",
    "\n",
    "    # Add the tokens of response as labels in the input dictionary of the model\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the preprocessing function to the dataset, generating the tokenized dataset \n",
    "dataset_tokenized = dataset.map(data_preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataset tokenized\n",
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized['train']['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized['train']['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Evaluate Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"punkt\" package is specifically for the task of tokenization, which involves splitting a text\n",
    "# into a list of sentences\n",
    "nltk.download(\"punkt\", quiet = True)\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ROUGE** metric (*Recall-Oriented Understudy for Gisting Evaluation*) is widely used to automatically evaluate the quality of machine-generated text summaries by comparing them to human-written reference summaries. It measures the overlap between n-grams, words, or sequences of words in the generated text and the reference text.\n",
    "\n",
    "### Common ROUGE Variants\n",
    "\n",
    "1. **ROUGE-N**:\n",
    "   - Measures the overlap of n-grams between the generated and reference texts.\n",
    "   - Example: ROUGE-1 (for unigrams), ROUGE-2 (for bigrams), etc.\n",
    "   - Formula:\n",
    "     \n",
    "     $\\text{ROUGE-N} = \\frac{\\sum_{S \\in \\text{Reference}} \\sum_{\\text{n-gram} \\in S} \\text{Count\\_overlap}(\\text{n-gram})}{\\sum_{S \\in \\text{Reference}} \\sum_{\\text{n-gram} \\in S} \\text{Count}(\\text{n-gram})}$\n",
    "     \n",
    "\n",
    "2. **ROUGE-L**:\n",
    "   - Based on the *Longest Common Subsequence* (LCS), measuring the longest sequence of words that appears in both the generated and reference texts.\n",
    "   - Useful because it accounts for word order without requiring the words to be contiguous.\n",
    "\n",
    "3. **ROUGE-W**:\n",
    "   - A variation of ROUGE-L that assigns weights to continuous subsequences, giving more importance to longer segments.\n",
    "\n",
    "4. **ROUGE-S** (or ROUGE-Skip):\n",
    "   - Measures co-occurrences of word pairs that appear in the same order but may be separated by other words.\n",
    "\n",
    "5. **ROUGE-SU**:\n",
    "   - Combines ROUGE-S with unigrams, adding more context to the evaluation.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "- **Recall**:\n",
    "  - Measures how much of the reference text is captured in the generated text.\n",
    "  - Useful for summarization tasks, as it prioritizes capturing essential information.\n",
    "\n",
    "- **Precision**:\n",
    "  - Measures how much of the generated text is present in the reference.\n",
    "  - Less commonly emphasized in ROUGE but still relevant.\n",
    "\n",
    "- **F1-Score**:\n",
    "  - Combines *Recall* and *Precision* to provide a balanced metric.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- Evaluating text summarization models.\n",
    "- Comparing generated texts in tasks like machine translation, captioning, or automated responses.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider the reference summary:  \n",
    "**\"The cat is on the roof\"**  \n",
    "Machine-generated summary:  \n",
    "**\"The cat sleeps on the roof\"**\n",
    "\n",
    "- **ROUGE-1 (Unigrams)**:  \n",
    "  - Unigrams in the reference: {The, cat, is, on, roof}  \n",
    "  - Unigrams in the generated text: {The, cat, sleeps, on, roof}  \n",
    "  - Overlap: {The, cat, on, roof}  \n",
    "  - Recall = 4/5 = 0.8 (80%)  \n",
    "  - Precision = 4/5 = 0.8 (80%)  \n",
    "  - F1-Score = 0.8 (80%)\n",
    "\n",
    "- **ROUGE-2 (Bigrams)**:  \n",
    "  - Bigrams in the reference: {The cat, cat is, is on, on the roof}  \n",
    "  - Bigrams in the generated text: {The cat, cat sleeps, sleeps on, on the roof}  \n",
    "  - Overlap: {The cat, on the roof}  \n",
    "  - Recall = 2/4 = 0.5 (50%)  \n",
    "  - Precision = 2/4 = 0.5 (50%)  \n",
    "  - F1-Score = 0.5 (50%)\n",
    "\n",
    "ROUGE is useful for automatically evaluating the quality of texts but does not capture semantic or creative nuances. Therefore, it is recommended as a complement to human evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the metric\n",
    "metric = evaluate.load('rouge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric calculate function\n",
    "def calculate_metric(eval_preds):\n",
    "\n",
    "    # Unpack the predictions and labels from the eval_preds argument\n",
    "    predictions, labels = eval_preds\n",
    "\n",
    "    # Replace all non--100 values ​​in labels with the padding token ID\n",
    "    labels = np.where(labels != -100,\n",
    "                      labels,\n",
    "                      tokenizer.pad_token_id)\n",
    "    \n",
    "    # Decode predictions to text, ignoring special tokens\n",
    "    decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Decode labels to text, ignoring special tokens\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Add a new line after each sentence to the decoded predictions, preparing them for ROUGE evaluation\n",
    "    decoded_predictions = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_predictions]\n",
    "    \n",
    "    # Add a new line after each label to the decoded predictions, preparing them for ROUGE evaluation\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "\n",
    "    # Calculate the ROUGE metric between predictions and decoded labels, using a stemmer\n",
    "    result = metric.compute(predictions = decoded_predictions,\n",
    "                            references = decoded_labels,\n",
    "                            use_stemmer = True)\n",
    "    \n",
    "    # Returns the result of ROUGE metric\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Seq2SeqTrainingArguments`** class from the `transformers` package is used to configure training parameters when fine-tuning sequence-to-sequence (Seq2Seq) models, such as those used in tasks like machine translation, text summarization, or conditional text generation.\n",
    "\n",
    "This class extends the base `TrainingArguments` class and adds specific arguments tailored for Seq2Seq model training, such as those based on **T5**, **BART**, and others.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Arguments**\n",
    "Here are the most relevant arguments:\n",
    "\n",
    "#### **General Arguments** (inherited from `TrainingArguments`):\n",
    "1. **`output_dir`**:\n",
    "   - Directory where models and checkpoints will be saved.\n",
    "   - Example: `output_dir=\"./results\"`\n",
    "\n",
    "2. **`evaluation_strategy`**:\n",
    "   - Strategy for evaluation during training. Options:\n",
    "     - `no`: No evaluation.\n",
    "     - `steps`: Evaluation at specific step intervals.\n",
    "     - `epoch`: Evaluation at the end of each epoch.\n",
    "\n",
    "3. **`per_device_train_batch_size`**:\n",
    "   - Batch size used for training on each device (CPU/GPU).\n",
    "\n",
    "4. **`learning_rate`**:\n",
    "   - Initial learning rate.\n",
    "\n",
    "5. **`num_train_epochs`**:\n",
    "   - Total number of training epochs.\n",
    "\n",
    "6. **`save_steps`**:\n",
    "   - Number of steps between each checkpoint save.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Seq2Seq-Specific Arguments**:\n",
    "1. **`predict_with_generate`**:\n",
    "   - Type: `bool`\n",
    "   - Indicates whether to use the `generate()` method to make predictions during evaluation.\n",
    "   - Very useful for tasks like translation or summarization, where the output is a generated sequence.\n",
    "\n",
    "2. **`generation_max_length`**:\n",
    "   - Type: `int`\n",
    "   - Maximum length of sequences generated during evaluation or prediction.\n",
    "\n",
    "3. **`generation_num_beams`**:\n",
    "   - Type: `int`\n",
    "   - Sets the number of beams used in beam search for sequence generation.\n",
    "   - Example: Setting it to `4` can improve the quality of generated text.\n",
    "\n",
    "4. **`label_smoothing_factor`**:\n",
    "   - Type: `float`\n",
    "   - Label smoothing factor used to prevent overfitting.\n",
    "   - Example: A value like `0.1` smooths the target probabilities.\n",
    "\n",
    "5. **`forced_bos_token_id` and `forced_eos_token_id`**:\n",
    "   - IDs of special tokens to enforce as the beginning (`BOS`) or end (`EOS`) of the generated sequence.\n",
    "   - Useful in scenarios where greater control over the model's output is required.\n",
    "\n",
    "6. **`length_penalty`**:\n",
    "   - Type: `float`\n",
    "   - Penalizes or rewards longer sequences during generation.\n",
    "   - Values less than 1 favor shorter sequences; values greater than 1 favor longer ones.\n",
    "\n",
    "---\n",
    "\n",
    "### **Usage Example**\n",
    "Here’s an example of how to set up arguments for Seq2Seq training:\n",
    "\n",
    "```python\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    generation_num_beams=4,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use**\n",
    "The **`Seq2SeqTrainingArguments`** class is essential when training Seq2Seq models using the `Trainer` provided by the `transformers` package. It offers a standardized interface to configure both general training aspects and specifics of text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train arguments\n",
    "training_args = Seq2SeqTrainingArguments(output_dir = \"train_results\",\n",
    "                                        evaluation_strategy = \"epoch\",\n",
    "                                        learning_rate = 3e-4,\n",
    "                                        logging_dir = \"logs_treino\",\n",
    "                                        logging_steps = 1,\n",
    "                                        per_device_train_batch_size = 4,\n",
    "                                        per_device_eval_batch_size = 2,\n",
    "                                        weight_decay = 0.01,\n",
    "                                        save_total_limit = 1,\n",
    "                                        num_train_epochs = 1,\n",
    "                                        predict_with_generate = True,\n",
    "                                        push_to_hub = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Seq2SeqTrainer`** class from the `transformers` package is a specialized version of the `Trainer` class designed specifically for training sequence-to-sequence (Seq2Seq) models. It is tailored for tasks like machine translation, text summarization, and conditional text generation, where both the input and output are sequences.\n",
    "\n",
    "This class simplifies the training and evaluation of Seq2Seq models by integrating features specific to generation tasks, such as beam search, sequence length constraints, and evaluation with the `generate` method.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features of `Seq2SeqTrainer`**\n",
    "1. **Integration with Generation**:\n",
    "   - Uses the model's `generate()` method for prediction during evaluation or inference, allowing evaluation metrics to be computed on generated sequences.\n",
    "\n",
    "2. **Support for Seq2Seq-Specific Metrics**:\n",
    "   - Metrics like ROUGE, BLEU, and others that rely on generated text can be directly integrated into the evaluation pipeline.\n",
    "\n",
    "3. **Handles Forced Tokens**:\n",
    "   - Supports forcing specific tokens (e.g., BOS/EOS tokens) at the start or end of generated sequences using arguments like `forced_bos_token_id` and `forced_eos_token_id`.\n",
    "\n",
    "4. **Extended Arguments**:\n",
    "   - Works seamlessly with `Seq2SeqTrainingArguments`, which includes additional parameters like `generation_max_length`, `generation_num_beams`, and `label_smoothing_factor`.\n",
    "\n",
    "5. **Label Smoothing**:\n",
    "   - Implements label smoothing during training to make the model more robust and prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Methods**\n",
    "#### 1. **`compute_loss`**:\n",
    "   - Computes the loss during training, optionally applying label smoothing if configured.\n",
    "\n",
    "#### 2. **`prediction_step`**:\n",
    "   - Overrides the base `Trainer`'s method to support predictions using `generate()` for Seq2Seq tasks.\n",
    "\n",
    "#### 3. **`evaluate`**:\n",
    "   - Evaluates the model using generated sequences instead of raw logits.\n",
    "   - Automatically applies `generation_max_length` and `generation_num_beams` for evaluation.\n",
    "\n",
    "#### 4. **`generate`**:\n",
    "   - Handles sequence generation using the model's `generate()` method, with support for various generation strategies like greedy search, beam search, or sampling.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Configuration Parameters**\n",
    "`Seq2SeqTrainer` inherits all parameters from `Trainer` and adds Seq2Seq-specific ones:\n",
    "\n",
    "1. **`tokenizer`**:\n",
    "   - Used to tokenize the input and decode generated sequences.\n",
    "\n",
    "2. **`predict_with_generate`**:\n",
    "   - Enables the use of the model's `generate()` method during evaluation.\n",
    "\n",
    "3. **`generation_max_length`**:\n",
    "   - Maximum length for generated sequences during evaluation or prediction.\n",
    "\n",
    "4. **`generation_num_beams`**:\n",
    "   - Number of beams for beam search in sequence generation.\n",
    "\n",
    "5. **`label_smoothing_factor`**:\n",
    "   - Factor for label smoothing during training.\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use**\n",
    "- Use `Seq2SeqTrainer` when training models for tasks where both the input and output are sequences, and you need additional support for generation and sequence-based metrics.\n",
    "- It is particularly suited for models like **T5**, **BART**, and **MBart**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the trainer\n",
    "trainer = Seq2SeqTrainer(model = model,\n",
    "                        args = training_args,\n",
    "                        train_dataset = dataset_tokenized[\"train\"],\n",
    "                        eval_dataset = dataset_tokenized[\"test\"],\n",
    "                        tokenizer = tokenizer,\n",
    "                        data_collator = data_collator,\n",
    "                        compute_metrics = calculate_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "trainer.save_model('model/saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUGE-1** measures the overlap of unigrams (individual words).\n",
    "\n",
    "**ROUGE-2** measures the overlap of bigrams (pairs of consecutive words).\n",
    "\n",
    "**ROUGE-L** measures the overlap of the longest common subsequence between the generated summary and the reference summary. This takes into account word order, but allows for gaps. Higher values ​​indicate better performance. ROUGE-L is calculated based on the similarity between the sequences, taking into account precision, recall, and the harmonic mean between them.\n",
    "\n",
    "Higher ROUGE values ​​indicate a greater similarity between the generated summary and the reference summary, which is generally interpreted as an indication of better summary quality. However, it is important to remember that no single metric can fully capture the quality of a summary, and it is useful to complement the assessment with qualitative analysis or other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='model/saved_model', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32011: AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32012: AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32013: AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32014: AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32015: AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32016: AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32017: AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32018: AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32019: AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32020: AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32021: AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32022: AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32023: AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32024: AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32025: AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32026: AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32027: AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32028: AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32029: AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32030: AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32031: AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32032: AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32033: AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32034: AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32035: AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32036: AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32037: AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32038: AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32039: AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32040: AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32041: AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32042: AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32043: AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32044: AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32045: AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32046: AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32047: AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32048: AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32049: AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32050: AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32051: AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32052: AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32053: AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32054: AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32055: AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32056: AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32057: AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32058: AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32059: AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32060: AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32061: AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32062: AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32063: AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32064: AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32065: AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32066: AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32067: AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32068: AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32069: AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32070: AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32071: AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32072: AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32073: AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32074: AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32075: AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32076: AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32077: AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32078: AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32079: AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32080: AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32081: AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32082: AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32083: AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32084: AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32085: AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32086: AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32087: AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32088: AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32089: AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32090: AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32091: AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32092: AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32093: AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32094: AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32095: AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32096: AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32097: AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32098: AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32099: AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the final tokenizer saved on the disk\n",
    "tokenizer_final = AutoTokenizer.from_pretrained('model/saved_model')\n",
    "\n",
    "print(tokenizer_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the final model saved on the disk\n",
    "model_final = AutoModelForSeq2SeqLM.from_pretrained('model/saved_model')\n",
    "\n",
    "print(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "input_text = 'Can I move out of state with my children if I have a custody agreement in the state?'\n",
    "\n",
    "# Tokenizing\n",
    "tokenized_input_text = tokenizer_final(input_text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the output (model prediction)\n",
    "tokenized_output_text = model_final.generate(tokenized_input_text, max_length = 100, temperature = 0.3, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,    71, 16701,  2791,    19,     3,     9, 13595, 11293,  2791,\n",
      "           344,     8,  2251,    12,     3,     9, 16701,  8641,     5,   156,\n",
      "            25,    43,     3,     9, 16701,  2791,    16,   286,     6,    25,\n",
      "            54,   888,    91,    13,   538,    28,    39,   502,     5,   611,\n",
      "             6,    34,    31,     7,   359,    12,  2232,    24,   284,   538,\n",
      "            65,   165,   293,  2219,  1918,  1735,    91,    13,   538,     5,\n",
      "           156,    25,    43,     3,     9, 16701,  2791,    16,   286,     6,\n",
      "            25,   164,   174,    12,  1132,     8,  1353,    13,     8,  2791,\n",
      "            12,  2082,     3,    99,    25,    54,   888,    91,    13,   538,\n",
      "             5,   156,    25,    43,     3,     9, 16701,  2791,    16,   286]])\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "print(tokenized_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodifing the output\n",
    "output_text = tokenizer_final.decode(tokenized_output_text[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Can I move out of state with my children if I have a custody agreement in the state?\n",
      "Answer:  A custody agreement is a legally binding agreement between the parties to a custody arrangement. If you have a custody agreement in place, you can move out of state with your children. However, it's important to note that each state has its own rules regarding moving out of state. If you have a custody agreement in place, you may need to review the terms of the agreement to determine if you can move out of state. If you have a custody agreement in place\n"
     ]
    }
   ],
   "source": [
    "print('Question: ', input_text)\n",
    "print('Answer: ', output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
